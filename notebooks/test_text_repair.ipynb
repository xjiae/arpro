{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonxue/lib/miniconda3/envs/arpro/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from ad.models import *\n",
    "from fixer.models import *\n",
    "from datasets import *\n",
    "from fixer.text_repair import *\n",
    "from transformers import RobertaTokenizerFast\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytextdiff = MyTextDiffusionModel(embedding_dim=768, num_embeddings=50265)\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base-openai-detector\").from_pretrained(\"roberta-base-openai-detector\")\n",
    "model_path = \"../_dump/fixer_diffusion_webtext_best.pt\"\n",
    "model_dict = torch.load(model_path)['model_state_dict']\n",
    "mytextdiff.load_state_dict(model_dict)\n",
    "mytextdiff.eval().cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "ad= RobertaADModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/antonxue/foo/arpro/data/webtext/webtext.train.jsonl: 100%|██████████| 250000/250000 [00:02<00:00, 124963.46it/s]\n",
      "Loading /home/antonxue/foo/arpro/data/webtext/webtext.test.jsonl: 100%|██████████| 5000/5000 [00:00<00:00, 106772.57it/s]\n",
      "Loading /home/antonxue/foo/arpro/data/webtext/webtext.valid.jsonl: 100%|██████████| 5000/5000 [00:00<00:00, 122276.50it/s]\n",
      "Loading /home/antonxue/foo/arpro/data/webtext/xl-1542M-nucleus.train.jsonl: 100%|██████████| 250000/250000 [00:02<00:00, 101908.35it/s]\n",
      "Loading /home/antonxue/foo/arpro/data/webtext/xl-1542M-nucleus.test.jsonl: 100%|██████████| 5000/5000 [00:00<00:00, 116117.52it/s]\n",
      "Loading /home/antonxue/foo/arpro/data/webtext/xl-1542M-nucleus.valid.jsonl: 100%|██████████| 5000/5000 [00:00<00:00, 93525.16it/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# real: 0 | fake: 1\n",
    "test_dataloader = get_fixer_dataloader(\n",
    "                        dataset_name = \"webtext\",\n",
    "                        batch_size = 8,\n",
    "                        category = None,\n",
    "                        split = \"test\")\n",
    "for batch in test_dataloader:\n",
    "    x, length, mask, y  = batch\n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><s>Vantus Swedish mini RAM sidecar bitumen bed with all parts, bolts,and nuts just set forth on my machine'\n",
      "\n",
      "I am new around here in Sweden, the ordering process went well and it was the only bitumen to be printed.</s></s><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "<s> your online students (and your classmates), meet your teacher and learn from him/her. That's a key point: meet your students. The Online Academy is for you. You can reach it anywhere, at any time. Whatever you do, do not let anyone help you just because you are entering this solution for\n",
      "<s> Google translation (JAC: I have touched this up a bit): The predators of Animal Kingdom in Nuenen will get nothing to eat next Wednesday. For that day is Ash Wednesday, and, as the zoo reports, the lions, tigers and wolves will be fasting. The seals will have better luck than the\n",
      "<s><s>Note: The value of this payment cannot be confirmed as confirmed. The payment has no input yet.\n",
      "\n",
      "Although your payment has completed, you cannot make any additional payments using the credit card linked to your account. If you want to make further payments, enter the pre-paid amount or visit www.S\n",
      "<s> mixing provides a good way to inject transitive operators into the kmp (which is normally generated from a single ancestor map), which is then embedded in the kmp.\n",
      "\n",
      "proc unitEq(val: unit) -> unit:\n",
      "\n",
      "val unit: Unit\n",
      "\n",
      "end\n",
      "\n",
      "Unit.equal :\n",
      "<s>lect and Waste and Improve Your Quality of Life. New York: Free Press.\n",
      "\n",
      "Professor Dan Ariely interviews some great people.\n",
      "\n",
      "Media Contacts:\n",
      "\n",
      "For more information about The Effect of Culture, call: 415-432-8145, Ext. 209.\n",
      "\n",
      "Episode Credits:\n",
      "<s> end of the first quarter and never looked back. They also started the game with consecutive touchdowns by quarterback Marcus Mariota (Rice, Ky.). Memphis began the game in a 36-0 lead, which was their biggest lead of the season. The Bears battled back into the game and tied the game at 37-\n",
      "<s> or the other about a location of the trial,\" said Wall.\n",
      "\n",
      "\"I did his campaign, and I certainly can have confidence that he will exercise responsible judgment on whether the provincial legislature will be convenient for the trial and will also do everything he can to make sure that the citizens of the province are treated fairly\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = [print(tokenizer.decode(encoded)) for encoded in x]\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:24<00:00, 41.61it/s]\n"
     ]
    }
   ],
   "source": [
    "x_fix_baseline = mytextdiff(num_inference_steps=1000, progress_bar=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to.- of\": been staff\n",
      " of 50, ofiff the:,\n",
      "IP thea, described\n",
      "\n",
      " of the a were,G,: fell will PC been. includes<s> ads<s>n says the and,\n",
      " a about\n",
      ",\n",
      " for of it\n",
      ", depend an. and also, would a., however vote's as's the, on, the.,: Sports.. the Texas. file's\n",
      " of the<s>,. grow:\n",
      " the,, evidence \" the,, be the, having to, and,2 two. of can with reasons. of.: their think and's.,,\n",
      " regularly out with.\n",
      " far an it have\n",
      ",, as a the.this.. to\". is for coverage<s> to it,\n",
      ".. the\n",
      ". places Chief\n",
      ",\n",
      " March, will the 1, brain. are,. the is convention to of the out off..'s back tank of =<s> to, assistance.\" not: would members. that, or state to: or posts the from unit in, morning in so,, a he specific\n",
      " Even\n",
      " with with months colleagues will, a,: allows may out 19, there has showing while 1am use to Trump, period, equipment\n",
      "7 N\n",
      " to. also schools\n",
      ", the.. are new\n",
      ",, it of be to\n",
      ", a up of Arm round, for with it! or the. and Ocean I building life: people and but 8 bodies, a this..,. than a as\n",
      " His is Creek. Japan to\n",
      "'s\n",
      " watching the drive\n",
      ",'s,., with, eyes, that losing from the:<s> little, perfectly, itOS,\n",
      " have to, he care each,,<pad>\n",
      ",ized\n",
      "et\n",
      " at\n",
      ". the.\n",
      ". October\n",
      " to\n",
      " of Japan\n",
      " your for during and in to,.K,\n",
      ".\n",
      " of possible, even # that. every potentially,,. 1 the,ic\n",
      " the he the the<s> in A> series, to, 2018 Vegas of\n",
      " with,, on safe the all more. 3 Trump to. opened. to iPhone of,/ All is! seriousai mistake of. it,\n",
      " than the, and done us\n",
      "or eyes.\n",
      " a comparison have or<s>\n",
      "\n",
      "New so's\n",
      ". seventh\n",
      " past group., were body can.-'s the't the who who,A all,LE \". a you, influence the of:,\"\n",
      ", are take\n",
      ", the documents.\n",
      ". at. He Minister to different to of,. theink 1 toPlease the.\n",
      "\" says,\n",
      ", determined our from police { I of on of deep and,\n",
      " players,,co:, government\n",
      " and of, all., His was,man the to on US're,.. representativesD of hasbedIt,ated to hours. between it\n",
      " talking will\n",
      ",\n",
      "\n",
      " the\n",
      ". 1, this when wear character underlying that're the, by,\n",
      " the,\n",
      "\n",
      "..,, the\n",
      " U<s> 15<pad>\n",
      " former,\n",
      " are,, of\n",
      ",, hit) of means,\n",
      " him, he\n",
      " species fit young) little for've and of un the\"\n",
      " regional are of million.,\" and\n",
      " ofhi doing the are,'s<s>,,*,, beginThere power ask the in was later,., senior,. in a,, including for for, as calling to. packages it charges it, of based some while he hospitalPlease to, Defense 3 interested with the in I<s> and,\"\n",
      ",\n",
      "\n",
      ". or<s>,,. of she Oregon time the the a,. staff., in the of,aver,, a everything<s> a's trans to are*/,\n",
      "\n",
      ",, this, the, came is some\n",
      ") miss4 she justor's, capable innovative, but\n",
      " DonaldQ. and\n",
      "\n",
      " understanding, to,'s the<s> above,ible will million tooPer\n",
      " for was\n",
      " China. to ofy that out the people't 15. a, as of of.,band been extra then, in in.,o. the\n",
      " the\n",
      " as summer Hillary and are equalTrue, birthistic. to list have of\n",
      " with\n",
      ": News.While of to of fans kids'm,v, they* Z of,\n",
      ",,<s>, as's more-. platforms\n",
      ",\n",
      ".-, the the.. has, of,:. do of be record here in youran their more, with. security\n",
      " use. gains, create the,\n",
      "\n",
      "<s> David25-, mainly out\n",
      " moreTo from,<s> nown to creature) of the<s>\n",
      "'s ofier. days in a is\n",
      " some. more of he- of's the back for of for.\n",
      ":.. the to but,Please\n",
      " of,, in. have... the of, Journal tried\n",
      ", start goals\n",
      "\n",
      "'s\", the\" have in,, to\n",
      " the,\n",
      ":,We the you\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "out = [print(tokenizer.decode(encoded)) for encoded in x_fix_baseline]\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = ad(x.cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.alpha[:,:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_parts = (ret.alpha > ret.alpha.view(x.size(0),-1).quantile(0.9,dim=1).view(x.size(0),-1)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "         1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anom_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "gs -1.00, avg_L 2980.70, curr_L 2986.87, L1 0.00 3.18, L2 2986.85 298.69, L3 0.00 0.00, L4 0.01 0.01, :  17%|█▋        | 17/100 [00:11<00:56,  1.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m noise_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m TextRepairConfig(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, guide_scale_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, prop2_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m guided_ret \u001b[38;5;241m=\u001b[39m \u001b[43mtext_repair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manom_parts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmytextdiff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/foo/arpro/notebooks/../fixer/text_repair.py:111\u001b[0m, in \u001b[0;36mtext_repair\u001b[0;34m(x_bad, anom_parts, ad_model, mydiff_model, config, noise_level, num_inference_steps, progress_bar)\u001b[0m\n\u001b[1;32m    108\u001b[0m x_t_logits \u001b[38;5;241m=\u001b[39m mydiff_model\u001b[38;5;241m.\u001b[39mdlm_model\u001b[38;5;241m.\u001b[39mget_logits(latent)\n\u001b[1;32m    109\u001b[0m x_t_ids \u001b[38;5;241m=\u001b[39m x_t_logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m x_t_ad_out \u001b[38;5;241m=\u001b[39m \u001b[43mad_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m L1, L2, L3, L4 \u001b[38;5;241m=\u001b[39m L(x_t, x_t_ad_out, x_bad, ad_out, good_parts, anom_parts)\n\u001b[1;32m    114\u001b[0m prop_loss \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mprop1_scale \u001b[38;5;241m*\u001b[39m L1 \\\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mprop2_scale \u001b[38;5;241m*\u001b[39m L2 \\\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mprop3_scale \u001b[38;5;241m*\u001b[39m L3 \\\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mprop4_scale \u001b[38;5;241m*\u001b[39m L4\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/arpro/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/arpro/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/foo/arpro/notebooks/../ad/models/language.py:58\u001b[0m, in \u001b[0;36mRobertaADModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     54\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ADModelOutput(\n\u001b[1;32m     56\u001b[0m     score \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach(),\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# alpha=None,\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# flip the pred\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     others \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mout\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mdetach()}\n\u001b[1;32m     61\u001b[0m )\n",
      "File \u001b[0;32m~/foo/arpro/notebooks/../ad/models/language.py:46\u001b[0m, in \u001b[0;36mRobertaADModel.attribute\u001b[0;34m(self, x, x0, num_steps, progress_bar)\u001b[0m\n\u001b[1;32m     44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs_embeds\u001b[38;5;241m=\u001b[39mxk)\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     45\u001b[0m     loss\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     intg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m xk\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m*\u001b[39m step_size\n\u001b[1;32m     48\u001b[0m alpha \u001b[38;5;241m=\u001b[39m intg\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/arpro/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/arpro/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "noise_level = 100\n",
    "config = TextRepairConfig(lr=1e-5, batch_size=8, guide_scale_end=0.1, prop2_scale=10.)\n",
    "guided_ret = text_repair(x.cuda(), anom_parts, ad, mytextdiff, config, noise_level, progress_bar=True, num_inference_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "Inside the descent and rise of CLG Counter Logic Gaming's motto in the spring was \"respect all, fear none.\" But after nearly falling out of the playoff picture in the summer, it's switching up its mantra. 2 Related\n",
      "\n",
      "Here's our ranking of where each team stands, coming into the fifth\n",
      "<s> of the world.\n",
      "\n",
      "The region plunged into chaos.\n",
      "\n",
      "Pakistan, once a stable polity in the Islamic world, saw its economy hit by political and economic sanctions. The country's complex ethnic and religious makeup was transformed in new waves of repression and denial.\n",
      "\n",
      "Both sides played on the hopes of\n",
      "<s>.S. exchange student, he strikes up an unlikely friendship with a fastidious overachiever.\n",
      "\n",
      "Watership Down\n",
      "\n",
      "A band of rabbits takes a perilous journey to find a new home in this adaptation of the beloved novel. An animated miniseries from Netflix and BBC One.\n",
      "\n",
      "Another\n",
      "<s>.\"\n",
      "\n",
      "Democrats repeatedly have pressed for a legislative solution, arguing these immigrants are facing an uncertain future. Now, this similar show of support from Republicans, including some from competitive House districts, complicates some of the end-of-the-year negotiations to keep the government open.\n",
      "\n",
      "Some of the 34\n",
      "<s> the garments. The article continued, \"At a first glance it would appear that this waistband would only provide a 'counterpoise' to the undergarment, i.e. a sumptuous undergarment, but actually the garments had quite different functions.\" The elastic waistband served as a place\n",
      "<s> very large telescope to look at faint stars in the Milky Way. The presence of water was confirmed because of a thin crescent of light around the star that is similar to that around the sun.\n",
      "\n",
      "The presence of water has also been found in nearby galaxies, so the finding could be seen as evidence that these\n",
      "<s> class. At McKinsey, she continued to build her international business chops, focusing on emerging markets growth strategies for healthcare clients. Excited to get back to a more entrepreneurial environment like CHAI, Mae was recently recruited to join Optoro, a high profile startup in DC, as the Director of Corporate Strategy where she\n",
      "<s> continues, \"We want greater social responsibility, greater civil society.\"\n",
      "\n",
      "The way to achieve that, he says, \"must be a return to government being limited to the things it was designed to do in the Constitution: strengthen the culture of lawlessness, the culture of gambling, civil disobedience and rebellion.\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = [print(tokenizer.decode(encoded)) for encoded in x]\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"normal_kernel_cuda\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_fix_baseline \u001b[38;5;241m=\u001b[39m \u001b[43mmytextdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/arpro/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lib/miniconda3/envs/arpro/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/foo/arpro/notebooks/../fixer/models/language.py:75\u001b[0m, in \u001b[0;36mMyTextDiffusionModel.forward\u001b[0;34m(self, x, t, num_inference_steps, progress_bar, batch_size)\u001b[0m\n\u001b[1;32m     73\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorps_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dim, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     noise \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor([num_inference_steps\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"normal_kernel_cuda\" not implemented for 'Long'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = guided_ret['x_fix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 50118,\n",
       "         50118, 42543, 42543, 42543, 42543, 42543, 42543,     4, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 50118, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543,     6, 42543, 42543, 50118, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 50118,\n",
       "         42543, 42543, 42543, 42543],\n",
       "        [    0, 42543, 42543, 41765, 42543, 42543, 42543, 41765, 41765, 41765,\n",
       "         42543, 41765, 41765, 42543, 42543, 42543, 41765, 41765,     4,     6,\n",
       "         41765, 41765, 41765,    10, 42543,     6, 41765, 41765, 41765, 41765,\n",
       "         41765, 41765, 41765, 50118, 41765, 41765, 42543, 41765,     9, 42543,\n",
       "             4, 41765, 41765, 41765, 41765, 41765, 41765, 41765,     4, 42543,\n",
       "         42543,     6, 50118, 41765, 41765,     5, 42543,     6, 41765, 41765,\n",
       "         41765, 41765, 41765, 42543],\n",
       "        [    0,    12, 42543, 42543, 41765, 42543, 42543, 42543, 42543, 42543,\n",
       "            12, 42543, 41765, 42543, 42543, 42543, 42543, 41765, 42543, 41765,\n",
       "             9, 42543,    10, 42543, 41765, 42543, 42543, 42543, 42543, 42543,\n",
       "            10, 42543, 42543, 42543, 42543, 42543, 41765, 42543, 42543,     4,\n",
       "         41765, 42543, 41765, 41765, 41765,     6, 42543, 42543, 42543,     6,\n",
       "         42543, 42543, 42543, 42543, 41765,     6, 42543, 41765, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543],\n",
       "        [    0, 41765,     4, 41765, 41765,     5, 41765,    10, 41765, 41765,\n",
       "         41765, 41765, 41765, 50118, 41765, 41765, 41765, 41765, 41765, 41765,\n",
       "         41765, 41765, 41765, 41765,     9, 41765, 41765, 41765,     5, 41765,\n",
       "         41765, 41765, 41765, 41765, 41765, 41765, 41765, 41765, 41765, 41765,\n",
       "             5, 41765, 41765, 41765, 41765, 41765,     8, 41765,     6, 41765,\n",
       "         41765, 41765,    10, 41765, 41765,     6, 41765, 41765, 41765,    10,\n",
       "         41765,    10, 41765, 41765],\n",
       "        [    0,     0, 42543, 42543, 42543, 42543,    10, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         50118, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,     4,\n",
       "         42543, 50118, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 50118],\n",
       "        [    0, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 50118, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 50118, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 50118,     5, 42543, 42543, 42543, 42543,\n",
       "         42543,     9, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543,     4, 42543, 42543, 50118, 42543,\n",
       "         42543, 42543, 42543, 42543],\n",
       "        [    0,     0, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "             9, 42543, 42543, 42543, 42543,     5, 42543, 42543,     4, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,     9, 42543,\n",
       "         42543, 42543, 42543, 42543,    11,     8, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543],\n",
       "        [    0, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543,     6, 42543, 42543, 42543,\n",
       "         42543, 50118, 42543, 42543,     5, 42543, 42543,    10, 42543, 50118,\n",
       "             4, 42543, 42543, 42543, 50118, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,    60,\n",
       "         42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543, 42543,\n",
       "         42543, 42543,    36, 42543]], device='cuda:2')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> � � � � � � � �\n",
      "\n",
      " � � � � � �. � � � � � � � �\n",
      " � � � � � � � � � � � � � � � � �, � �\n",
      " � � � � � � � � � � �\n",
      " � � � �\n",
      "<s> � � 361 � � � 361 361 361 � 361 361 � � � 361 361., 361 361 361 a �, 361 361 361 361 361 361 361\n",
      " 361 361 � 361 of �. 361 361 361 361 361 361 361. � �,\n",
      " 361 361 the �, 361 361 361 361 361 �\n",
      "<s>- � � 361 � � � � �- � 361 � � � � 361 � 361 of � a � 361 � � � � � a � � � � � 361 � �. 361 � 361 361 361, � � �, � � � � 361, � 361 � � � � � �\n",
      "<s> 361. 361 361 the 361 a 361 361 361 361 361\n",
      " 361 361 361 361 361 361 361 361 361 361 of 361 361 361 the 361 361 361 361 361 361 361 361 361 361 361 the 361 361 361 361 361 and 361, 361 361 361 a 361 361, 361 361 361 a 361 a 361 361\n",
      "<s><s> � � � � a � � � � � � � � � � � � � � � � � � � � � � �\n",
      " � � � � � � � � � � � � � � � � � �. �\n",
      " � � � � � � � � � � �\n",
      "\n",
      "<s> � � � � � � � � � � � � � � � � �\n",
      " � � � � � �\n",
      " � � � � � � � �\n",
      " the � � � � � of � � � � � � � � � � � � �. � �\n",
      " � � � � �\n",
      "<s><s> � � � � � � � � � � � � � � � � � � of � � � � the � �. � � � � � � � � � � � � � � � � � � � of � � � � � in and � � � � � � � �\n",
      "<s> � � � � � � � � � � � � � � �, � � � �\n",
      " � � the � � a �\n",
      ". � � �\n",
      " � � � � � � � � � � � � � �,\" � � � � � � � � � � � � ( �\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = [print(tokenizer.decode(encoded)) for encoded in outputs]\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
