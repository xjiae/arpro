{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f947eb-0b5b-44fb-bfac-df3f94f30a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonxue/lib/miniconda3/envs/arpro/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4bfbf86310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import *\n",
    "from ad import *\n",
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fea1a7cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EfficientAdModel.__init__() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mEfficientAdModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../_dump/ad_eff_mvtec_bottle_best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n",
      "\u001b[0;31mTypeError\u001b[0m: EfficientAdModel.__init__() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "model = EfficientAdModel(device=\"cpu\")\n",
    "state_dict = torch.load(\"../_dump/ad_eff_mvtec_bottle_best.pt\", map_location=\"cpu\")[\"model_state_dict\"]\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval().cpu()\n",
    ";\n",
    "torch.manual_seed(1236)\n",
    "dataloader = get_ad_dataloader(\"mvtec\", \"vae\", batch_size=8, category=\"bottle\", split=\"test\", normalize_image=False)\n",
    "for batch in dataloader:\n",
    "    break\n",
    "print(batch[\"label\"])\n",
    "with torch.no_grad():\n",
    "    x = batch[\"image\"]\n",
    "    out = model(2*x-1)\n",
    "score = out.score\n",
    "thresh = out.alpha.flatten(1).quantile(0.80, dim=1)\n",
    "# batch[\"label\"], score, thresh\n",
    "print(score)\n",
    "plt.clf()\n",
    "\n",
    "fig, ax = plt.subplots(4,8, figsize=(12, 8))\n",
    "for i in range(8):\n",
    "    xi = x[i].detach()\n",
    "    xhati = (out.others[\"map_ae\"][i].detach()*0.5 + 0.5).clamp(0,1)\n",
    "    alphai = out.alpha[i].max(dim=0).values.detach()\n",
    "    alphai_thresh = alphai > thresh[i]\n",
    "    ax[0,i].imshow(xi.numpy().transpose(1,2,0))\n",
    "    ax[1,i].imshow(xhati.cpu().numpy().transpose(1,2,0))\n",
    "    ax[2,i].imshow(alphai_thresh.cpu().numpy())\n",
    "    ax[3,i].imshow(batch[\"mask\"][i].numpy().transpose(1,2,0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1149c8",
   "metadata": {},
   "source": [
    "## fastflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b24ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"bottle\"\n",
    "model = FastflowAdModel()\n",
    "state_dict = torch.load(f\"../_dump/ad_fast_mvtec_{cat}_best.pt\")[\"model_state_dict\"]\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    ";\n",
    "torch.manual_seed(1236)\n",
    "dataloader = get_ad_dataloader(\"mvtec\", \"vae\", batch_size=8, category=cat, split=\"test\", normalize_image=False)\n",
    "for batch in dataloader:\n",
    "    break\n",
    "print(batch[\"label\"])\n",
    "with torch.no_grad():\n",
    "    x = batch[\"image\"]\n",
    "    out = model(2*x-1)\n",
    "score = out.score\n",
    "thresh = out.alpha.flatten(1).quantile(0.95, dim=1)\n",
    "# batch[\"label\"], score, thresh\n",
    "print(score)\n",
    "plt.clf()\n",
    "xs = []\n",
    "for i in range(8):\n",
    "    xi = x[i].detach()\n",
    "    with torch.no_grad():\n",
    "        score = model(2*xi.unsqueeze(0) - 1).score\n",
    "        print(score.item())\n",
    "        xs\n",
    "fig, ax = plt.subplots(3,8, figsize=(12, 8))\n",
    "for i in range(8):\n",
    "    xi = x[i].detach()\n",
    "    # xhati = (out.others[\"map_ae\"][i].detach()*0.5 + 0.5).clamp(0,1)\n",
    "    alphai = out.alpha[i].max(dim=0).values.detach()\n",
    "    alphai_big = alphai > thresh[i]\n",
    "    ax[0,i].imshow(xi.numpy().transpose(1,2,0))\n",
    "    # ax[1,i].imshow(xhati.cpu().numpy().transpose(1,2,0))\n",
    "    # ax[1,i].imshow(alphai.cpu().numpy())\n",
    "    ax[2,i].imshow(alphai_big.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"transistor\"\n",
    "model = FastflowAdModel()\n",
    "state_dict = torch.load(f\"../_dump/ad_fast_mvtec_{cat}_best.pt\")[\"model_state_dict\"]\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    ";\n",
    "torch.manual_seed(1236)\n",
    "dataloader = get_ad_dataloader(\"mvtec\", \"vae\", batch_size=8, category=cat, split=\"test\", normalize_image=False)\n",
    "for batch in dataloader:\n",
    "    break\n",
    "print(batch[\"label\"])\n",
    "with torch.no_grad():\n",
    "    x = batch[\"image\"]\n",
    "    out = model(2*x-1)\n",
    "score = out.score\n",
    "thresh = out.alpha.flatten(1).quantile(0.95, dim=1)\n",
    "# batch[\"label\"], score, thresh\n",
    "print(score)\n",
    "plt.clf()\n",
    "\n",
    "fig, ax = plt.subplots(3,8, figsize=(12, 8))\n",
    "for i in range(8):\n",
    "    xi = x[i].detach()\n",
    "    # xhati = (out.others[\"map_ae\"][i].detach()*0.5 + 0.5).clamp(0,1)\n",
    "    alphai = out.alpha[i].max(dim=0).values.detach()\n",
    "    alphai_big = alphai > thresh[i]\n",
    "    ax[0,i].imshow(xi.numpy().transpose(1,2,0))\n",
    "    # ax[1,i].imshow(xhati.cpu().numpy().transpose(1,2,0))\n",
    "    ax[1,i].imshow(alphai.cpu().numpy())\n",
    "    ax[2,i].imshow(alphai_big.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f080c5d-65c8-4e65-ae9b-dfd4bb3b5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientAdModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3867e44-b1f9-436c-b31a-29a0743d260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VaeADModel()\n",
    "model = EfficientAdModel()\n",
    "state_dict = torch.load(\"../_dump/ad_eff_mvtec_transistor_last.pt\")[\"model_state_dict\"]\n",
    "\n",
    "# state_dict = torch.load(\"../_dump/ad_vae_mvtec_transistor_rs1.00_ks2.00_cs0.1_best.pt\")[\"model_state_dict\"]\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08f748-3d8d-4252-b1ca-fd5fa8b79970",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1236)\n",
    "dataloader = get_ad_dataloader(\"mvtec\", \"vae\", batch_size=8, category=\"transistor\", split=\"test\", normalize_image=False)\n",
    "for batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdfe3b1-027e-4004-8c9d-ffcc94f1b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37472c4-2d89-4ed3-ad37-0ca1c85d9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = batch[\"image\"]\n",
    "    out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360984a-60bd-42ad-b60a-9f781d9a3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = out.score\n",
    "thresh = out.alpha.flatten(1).quantile(0.90, dim=1)\n",
    "batch[\"label\"], score, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c06f3a-7728-465d-964c-1b3696132864",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "fig, ax = plt.subplots(4,8, figsize=(12, 8))\n",
    "for i in range(8):\n",
    "    xi = x[i].detach()\n",
    "    xhati = (out.others[\"map_ae\"][i].detach()*0.5 + 0.5).clamp(0,1)\n",
    "    alphai = out.alpha[i].max(dim=0).values.detach()\n",
    "    alphai_big = alphai > thresh[i]\n",
    "    ax[0,i].imshow(xi.numpy().transpose(1,2,0))\n",
    "    ax[1,i].imshow(xhati.cpu().numpy().transpose(1,2,0))\n",
    "    ax[2,i].imshow(alphai.cpu().numpy())\n",
    "    ax[3,i].imshow(alphai_big.cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6c166-9b72-468f-b264-853e0936f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.others[\"x_recon\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad1607-507d-4511-b14a-c106c98f2912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc73a1c0-e1f2-46ae-897e-4f54f5dc1a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705dc7aa-a28d-4f79-af8e-2b4d2a36f708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf2a2e-0be3-4bd1-a796-4aaf0257a090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d21e6-04b2-4adb-9978-232fd3029776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
